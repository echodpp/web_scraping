# web_scraping
This is a step-step scraping data from websites and save in different format
* First download scrapy
* Second scrpay startproject <project_name>
* then within your new project file run scrapy genspider name name.mitre.org(a default path)
* with your spider folder open a name.py file
* if you wanna to scraping locally wegt <url>
three problems you might encounter when parsing websites on the internet/or thousands of URLs to parse
Network issues/
Websites changing and breaking the parsing/
Websites being unavailable or timing out
--wget <url>
